{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5X_UZ62IpMI"
   },
   "source": [
    "# INSTALL REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3251,
     "status": "ok",
     "timestamp": 1648811577942,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "OiCBf045Fxs5",
    "outputId": "aee6dcf2-0ed6-49d6-9915-368550d23ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1648811580688,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "VfFJlX78OAh5",
    "outputId": "b03f2b6e-ed6e-457e-8213-c0ab25bbd6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "# for XLNet\n",
    "\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2973,
     "status": "ok",
     "timestamp": 1648811583660,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "VPQia2NjWfII",
    "outputId": "ae54e370-b363-4417-ade1-0b6cb29bd8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.11)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.8)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAnXdrLQI0Cf"
   },
   "source": [
    "# GOOGLE MOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3411,
     "status": "ok",
     "timestamp": 1648811587068,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "asmIBqBsF-Y6",
    "outputId": "9b7e5633-da48-4a71-8944-c41ba23cabeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "PATH = './drive/MyDrive/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1648811587069,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "Lkq64JwCG5-s",
    "outputId": "97a9a7e2-bef9-44b2-94c1-fce32c5e07ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/groom_project1\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/groom_project1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1648811587069,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "Y25vO7PrG-GW",
    "outputId": "11085b98-47d0-4675-e360-c8670048af57"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/groom_project1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPhgURY0I5yf"
   },
   "source": [
    "# IMPORT REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3958,
     "status": "ok",
     "timestamp": 1648811591019,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "0DJZhXDiF_q8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    Adafactor,\n",
    ")\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "import wandb\n",
    "\n",
    "# import costumized modules\n",
    "from compute import compute_acc\n",
    "from visualize_score import plot_graph\n",
    "from dump_datasets import mk_dataset, mk_dataset_xlnet\n",
    "from dump_models import load_model, load_model_xlnet\n",
    "from evaluate import test_model\n",
    "from data_processing import regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s6-hdcnJE4o"
   },
   "source": [
    "#CREATE FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1648811591020,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "zpwJUy-bGBGV"
   },
   "outputs": [],
   "source": [
    "# create required folders if not exists\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    " \n",
    "createFolder('./best_models')\n",
    "createFolder('./dump_datasets')\n",
    "createFolder('./dump_models_tokenizer')\n",
    "createFolder('./scores')\n",
    "createFolder('./submissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MF56rfhfJIRV"
   },
   "source": [
    "# FIX SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648811591021,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "X4M_6OCAGC5r"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed:int = 1004):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgGB8K4yJNUy"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4072,
     "status": "ok",
     "timestamp": 1648811595081,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "RBdaD3ZYGC3U",
    "outputId": "0b58b73c-4c75-469e-cfe9-7863f521398d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dump_models_tokenizer/bert-base-uncased.p\n",
      "model exists => just load model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test various models\n",
    "\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "# MODEL_NAME = 'bert-large-uncased'\n",
    "# MODEL_NAME = 'xlnet-base-cased'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "assert str(device) == 'cuda'\n",
    "\n",
    "\n",
    "# by using pickle, load dump file if exist, else make dump file and load\n",
    "# load for bert(uncased) or xlnet model(cased)\n",
    "\n",
    "try:\n",
    "    with open('./dump_models_tokenizer/' + MODEL_NAME + '.p', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        tokenizer = pickle.load(f)\n",
    "        print('./dump_models_tokenizer/' + MODEL_NAME + '.p')\n",
    "    print('model exists => just load model')\n",
    "except:\n",
    "    print('exeption occur => download model')\n",
    "    if MODEL_NAME == 'bert-base-uncased':\n",
    "        model, tokenizer = load_model(MODEL_NAME)\n",
    "    elif MODEL_NAME == 'xlnet-base-cased':\n",
    "        model, tokenizer = load_model_xlnet(MODEL_NAME)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T7lNCeDJQQY"
   },
   "source": [
    "# HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1648811595082,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "QsvhsrAkGC1A",
    "outputId": "becab513-e33b-4bb6-a7b2-0ca7fa7204d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE=256\n",
    "EVAL_BATCH_SIZE=256\n",
    "TRAIN_EPOCH = 3\n",
    "\n",
    "LEARNING_RATE = 5e-5\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "# optimizer = Adafactor(model.parameters(), lr=LEARNING_RATE,\n",
    "#                     eps=(1e-30, 1e-3), decay_rate=-0.8, clip_threshold=1.0,\n",
    "#                     beta1=None,\n",
    "#                     weight_decay=0.0,\n",
    "#                     relative_step=False,\n",
    "#                     scale_parameter=False,\n",
    "#                     warmup_init=False,)\n",
    "# scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "#                                             num_warmup_steps=int(1732*TRAIN_EPOCH*0.1),\n",
    "#                                             num_training_steps=1732*TRAIN_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqrBw8DT6zM2"
   },
   "source": [
    "# WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1648811596610,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "ivKiMQWk7WAR",
    "outputId": "8311e48c-91f3-4807-eb21-2fcd724194e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 6074,
     "status": "ok",
     "timestamp": 1648811602676,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "NWHyxG8UWxEs",
    "outputId": "c86275e7-2c04-4907-849e-d4f82a275eb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/drive/MyDrive/groom_project1/wandb/run-20220401_111318-2gubpt8i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chohs1221/my-test-project/runs/2gubpt8i\" target=\"_blank\">curious-fire-12</a></strong> to <a href=\"https://wandb.ai/chohs1221/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/chohs1221/my-test-project/runs/2gubpt8i?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9231c76950>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.init(project=\"test-project\", entity=\"goorm_team_2\")\n",
    "wandb.init(project=\"my-test-project\", entity=\"chohs1221\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648811602676,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "LhQQiGsq8S47"
   },
   "outputs": [],
   "source": [
    "RUNNAME = 'realfinal_bert_ep3_' + str(LEARNING_RATE)\n",
    "wandb.run.name = RUNNAME\n",
    "wandb.config.learning_rate = LEARNING_RATE\n",
    "wandb.config.epochs = TRAIN_EPOCH\n",
    "wandb.config.batch_size = TRAIN_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL9a89s6JSSW"
   },
   "source": [
    "# LOAD DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648811602677,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "O6OctK41GCyh",
    "outputId": "b9c46fea-2c66-4852-a760-493736f93c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset exists => just load datasets\n"
     ]
    }
   ],
   "source": [
    "# by using pickle, load dump file if exist, else make dump file and load\n",
    "# load for bert(uncased) or xlnet model(cased)\n",
    "\n",
    "try:\n",
    "    if  MODEL_NAME == 'bert-base-uncased':\n",
    "        with open('./dump_datasets/train_dev_dumps.p', 'rb') as f:\n",
    "            train_pos = pickle.load(f)\n",
    "            train_neg = pickle.load(f)\n",
    "            dev_pos = pickle.load(f)\n",
    "            dev_neg = pickle.load(f)\n",
    "        print('dataset exists => just load datasets')\n",
    "    elif  MODEL_NAME == 'xlnet-base-cased':\n",
    "        with open('./dump_datasets/train_dev_dumps_xlnet.p', 'rb') as f:\n",
    "            train_pos = pickle.load(f)\n",
    "            train_neg = pickle.load(f)\n",
    "            dev_pos = pickle.load(f)\n",
    "            dev_neg = pickle.load(f)\n",
    "        print('dataset exists => just load datasets')\n",
    "except:\n",
    "    print('exeption occur => make datasets')\n",
    "    train_pos, train_neg, dev_pos, dev_neg = mk_dataset()\n",
    "    if MODEL_NAME == 'bert-base-uncased':\n",
    "        train_pos, train_neg, dev_pos, dev_neg = mk_dataset()\n",
    "    elif MODEL_NAME == 'xlnet-base-cased':\n",
    "        train_pos, train_neg, dev_pos, dev_neg = mk_dataset_xlnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-LaQPSMJYsn"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648811602677,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "4XyN7tiYGiSr",
    "outputId": "47482719-85c2-455e-e025-b38bac43fbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"windows have n't been cleaned in years you can see scum on them .\\n\",\n",
       " 'waitresses are slow .\\n',\n",
       " 'just a mess avoid at all costs !\\n',\n",
       " 'bad !\\n',\n",
       " 'now pizza is beyond awful and wings are down there with its level .\\n',\n",
       " 'walked out of this place after _num_ min of no service .\\n',\n",
       " \"the place was n't even busy at this time .\\n\",\n",
       " 'never will i be back to this place .\\n',\n",
       " 'this place is awful !\\n',\n",
       " 'not the food but the service .\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_neg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648811602677,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "yISja4bWGCwS"
   },
   "outputs": [],
   "source": [
    "# Remove '_num_', special symbols(!@#%$% ..) in datasets\n",
    "\n",
    "# train_pos = regular(train_pos)\n",
    "# train_neg = regular(train_neg)\n",
    "# dev_pos = regular(dev_pos)\n",
    "# dev_neg = regular(dev_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648811602677,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "aEf2JRzGGsCA",
    "outputId": "9b31afeb-27d0-461c-d1e7-9f1e2035aa96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"windows have n't been cleaned in years you can see scum on them .\\n\",\n",
       " 'waitresses are slow .\\n',\n",
       " 'just a mess avoid at all costs !\\n',\n",
       " 'bad !\\n',\n",
       " 'now pizza is beyond awful and wings are down there with its level .\\n',\n",
       " 'walked out of this place after _num_ min of no service .\\n',\n",
       " \"the place was n't even busy at this time .\\n\",\n",
       " 'never will i be back to this place .\\n',\n",
       " 'this place is awful !\\n',\n",
       " 'not the food but the service .\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_neg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648811602678,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "52s-TxF4Us9A"
   },
   "outputs": [],
   "source": [
    "# use train, valid datasets for training\n",
    "\n",
    "# train_pos = train_pos + dev_pos\n",
    "# train_neg = train_neg + dev_neg\n",
    "# len(train_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16_--kIMJbZA"
   },
   "source": [
    "# TOKENIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 131966,
     "status": "ok",
     "timestamp": 1648811734639,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "pP5IkQA-GCt9"
   },
   "outputs": [],
   "source": [
    "# seperate encoding to preprocess data before encoding\n",
    "\n",
    "train_pos = [tokenizer.encode(line) for line in train_pos]\n",
    "train_neg = [tokenizer.encode(line) for line in train_neg]\n",
    "dev_pos = [tokenizer.encode(line) for line in dev_pos]\n",
    "dev_neg = [tokenizer.encode(line) for line in dev_neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLJLDMjJJc-X"
   },
   "source": [
    "# MAKE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1648811735219,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "0NvG4M4SGCre"
   },
   "outputs": [],
   "source": [
    "# concatenate pos, neg dataset, costomize magic mathod\n",
    "\n",
    "class SentimentDataset(object):\n",
    "    def __init__(self, pos, neg):\n",
    "        self.data = [pos_sent for pos_sent in pos] + [neg_sent for neg_sent in neg]\n",
    "        self.label = [[1] for _ in range(len(pos))] + [[0] for _ in range(len(neg))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        return np.array(sample), np.array(self.label[index])\n",
    "\n",
    "train_dataset = SentimentDataset(train_pos, train_neg)\n",
    "dev_dataset = SentimentDataset(dev_pos, dev_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBtcDb_JJgDI"
   },
   "source": [
    "# DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648811735220,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "_W2NP0EtGCpI"
   },
   "outputs": [],
   "source": [
    "# argsort deleted <- no reason to sort\n",
    "# attention masking for padding token\n",
    "\n",
    "def collate_fn_style(samples):\n",
    "    input_ids, labels = zip(*samples)\n",
    "    max_len = max(len(input_id) for input_id in input_ids)\n",
    "\n",
    "    attention_mask = torch.tensor([[1] * len(input_id) + [0] * (max_len - len(input_id)) for input_id in input_ids])\n",
    "    input_ids = pad_sequence([torch.tensor(input_id) for input_id in input_ids], batch_first=True)\n",
    "    token_type_ids = torch.tensor([[0] * len(input_id) for input_id in input_ids])\n",
    "    position_ids = torch.tensor([list(range(len(input_id))) for input_id in input_ids])\n",
    "    labels = torch.tensor(np.stack(labels, axis=0))\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, position_ids, labels\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=TRAIN_BATCH_SIZE,\n",
    "                                           shuffle=True, \n",
    "                                           collate_fn=collate_fn_style,\n",
    "                                           pin_memory=True, num_workers=2)\n",
    "\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, \n",
    "                                         batch_size=EVAL_BATCH_SIZE,\n",
    "                                         shuffle=False, \n",
    "                                         collate_fn=collate_fn_style,\n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1648811735220,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "TrCtKxBToj3f",
    "outputId": "42a0b379-67f6-483f-bd7d-4a39d8779dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZvq41xfJif7"
   },
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 797046,
     "status": "error",
     "timestamp": 1648812532262,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "EaiyTjucGCmq",
    "outputId": "88b5a8cf-e4ed-45b1-a9f5-48ef90ad63ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 18/1732 [00:12<40:43,  1.43s/batch, acc=0.965, loss=0.102]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.956884765625\n",
      "LOSS for lowest valid acc:  tensor(0.1374, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 35/1732 [00:24<39:58,  1.41s/batch, acc=0.945, loss=0.157]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.959423828125\n",
      "LOSS for lowest valid acc:  tensor(0.1136, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 52/1732 [00:36<39:41,  1.42s/batch, acc=0.984, loss=0.0618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.964111328125\n",
      "LOSS for lowest valid acc:  tensor(0.1033, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4%|▍         | 69/1732 [00:48<38:48,  1.40s/batch, acc=0.949, loss=0.126]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.95908203125\n",
      "LOSS for lowest valid loss:  tensor(0.1058, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▍         | 86/1732 [01:00<38:48,  1.41s/batch, acc=0.965, loss=0.0759]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.95966796875\n",
      "LOSS for lowest valid loss:  tensor(0.1043, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|▌         | 103/1732 [01:12<39:08,  1.44s/batch, acc=0.973, loss=0.0841]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.9701171875\n",
      "LOSS for lowest valid acc:  tensor(0.0853, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   7%|▋         | 120/1732 [01:24<38:02,  1.42s/batch, acc=0.965, loss=0.104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.967041015625\n",
      "LOSS for lowest valid loss:  tensor(0.0936, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|▊         | 137/1732 [01:36<37:09,  1.40s/batch, acc=0.977, loss=0.0623]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.970751953125\n",
      "LOSS for lowest valid acc:  tensor(0.0796, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▉         | 171/1732 [01:59<36:31,  1.40s/batch, acc=0.953, loss=0.111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.9732421875\n",
      "LOSS for lowest valid acc:  tensor(0.0789, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|█         | 188/1732 [02:11<36:36,  1.42s/batch, acc=0.957, loss=0.109]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.969873046875\n",
      "LOSS for lowest valid loss:  tensor(0.0839, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12%|█▏        | 205/1732 [02:23<35:52,  1.41s/batch, acc=0.988, loss=0.0484]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.975537109375\n",
      "LOSS for lowest valid acc:  tensor(0.0745, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  13%|█▎        | 222/1732 [02:35<35:32,  1.41s/batch, acc=0.965, loss=0.0722]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.97255859375\n",
      "LOSS for lowest valid loss:  tensor(0.0777, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17%|█▋        | 290/1732 [03:23<34:02,  1.42s/batch, acc=0.969, loss=0.0635]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.973193359375\n",
      "LOSS for lowest valid loss:  tensor(0.0774, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|█▊        | 307/1732 [03:35<34:05,  1.44s/batch, acc=0.965, loss=0.0904]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.972119140625\n",
      "LOSS for lowest valid loss:  tensor(0.0731, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|█▉        | 341/1732 [03:59<32:58,  1.42s/batch, acc=0.98, loss=0.0482]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.97666015625\n",
      "LOSS for lowest valid acc:  tensor(0.0658, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  21%|██        | 358/1732 [04:11<32:28,  1.42s/batch, acc=0.977, loss=0.0567]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.975927734375\n",
      "LOSS for lowest valid loss:  tensor(0.0665, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  24%|██▎       | 409/1732 [04:47<31:24,  1.42s/batch, acc=0.977, loss=0.0764]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.9771484375\n",
      "LOSS for lowest valid acc:  tensor(0.0651, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  30%|███       | 528/1732 [06:10<28:32,  1.42s/batch, acc=0.98, loss=0.0721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.978857421875\n",
      "LOSS for lowest valid acc:  tensor(0.0649, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  34%|███▍      | 596/1732 [06:58<26:41,  1.41s/batch, acc=0.98, loss=0.0692]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.975927734375\n",
      "LOSS for lowest valid loss:  tensor(0.0620, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38%|███▊      | 664/1732 [07:45<25:13,  1.42s/batch, acc=0.98, loss=0.0666]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.976025390625\n",
      "LOSS for lowest valid loss:  tensor(0.0610, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  40%|████      | 698/1732 [08:09<24:55,  1.45s/batch, acc=0.961, loss=0.0883]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.978125\n",
      "LOSS for lowest valid loss:  tensor(0.0576, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|████▏     | 715/1732 [08:21<23:53,  1.41s/batch, acc=0.973, loss=0.0541]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for lowest valid loss:  0.978857421875\n",
      "LOSS for lowest valid loss:  tensor(0.0570, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  55%|█████▌    | 953/1732 [11:08<18:18,  1.41s/batch, acc=0.953, loss=0.118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.978955078125\n",
      "LOSS for lowest valid acc:  tensor(0.0584, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  62%|██████▏   | 1072/1732 [12:31<15:41,  1.43s/batch, acc=0.965, loss=0.0846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY for highest valid acc:  0.97900390625\n",
      "LOSS for lowest valid acc:  tensor(0.0563, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66%|██████▌   | 1139/1732 [13:16<06:54,  1.43batch/s, acc=0.977, loss=0.0429]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5721099a9cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0mbatch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-5721099a9cad>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0mbatch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# record datas for highest accuracy & lowest loss\n",
    "\n",
    "lowest_valid_loss = 9999.\n",
    "highest_valid_acc = 0.\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "\n",
    "temp_train_acc = []\n",
    "temp_train_loss = []\n",
    "\n",
    "#train model\n",
    "\n",
    "model.train()\n",
    "for epoch in range(TRAIN_EPOCH):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
    "\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            position_ids = position_ids.to(device)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           token_type_ids=token_type_ids,\n",
    "                           position_ids=position_ids,\n",
    "                           labels=labels)\n",
    "\n",
    "            loss = output.loss\n",
    "            \n",
    "            logits = output.logits\n",
    "            batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
    "            batch_labels = [int(example) for example in labels]\n",
    "            \n",
    "            acc = compute_acc(batch_predictions, batch_labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            tepoch.set_postfix(acc=acc, loss=loss.item())\n",
    "            \n",
    "            temp_train_acc.append(acc)\n",
    "            temp_train_loss.append(loss.item())\n",
    "            if iteration != 0 and iteration % int(len(train_loader) / 100) == 0:\n",
    "\n",
    "                # evaluate model\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_acc = []\n",
    "                    val_loss = []\n",
    "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in dev_loader:\n",
    "                        input_ids = input_ids.to(device)\n",
    "                        attention_mask = attention_mask.to(device)\n",
    "                        token_type_ids = token_type_ids.to(device)\n",
    "                        position_ids = position_ids.to(device)\n",
    "                        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "                        output = model(input_ids=input_ids,\n",
    "                                    attention_mask=attention_mask,\n",
    "                                    token_type_ids=token_type_ids,\n",
    "                                    position_ids=position_ids,\n",
    "                                    labels=labels)\n",
    "\n",
    "                        logits = output.logits\n",
    "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
    "                        batch_labels = [int(example) for example in labels]\n",
    "\n",
    "                        val_acc.append(compute_acc(batch_predictions, batch_labels))\n",
    "                        val_loss.append(output.loss)\n",
    "\n",
    "\n",
    "                # compute accuracy, loss for train, valid datasets and record\n",
    "                mean_train_acc = sum(temp_train_acc) / len(temp_train_acc)\n",
    "                mean_train_loss = sum(temp_train_loss) / len(temp_train_loss)\n",
    "                mean_val_acc = sum(val_acc) / len(val_acc)\n",
    "                mean_val_loss = sum(val_loss) / len(val_loss)\n",
    "\n",
    "                train_acc.append(mean_train_acc)\n",
    "                train_loss.append(mean_train_loss)\n",
    "                valid_acc.append(mean_val_acc)\n",
    "                valid_loss.append(mean_val_loss)\n",
    "\n",
    "                temp_train_acc = []\n",
    "                temp_train_loss = []\n",
    "                \n",
    "\n",
    "                # WANDB\n",
    "                wandb.log({\"train_loss\": mean_train_loss,\n",
    "                           'train_acc': mean_train_acc,\n",
    "                           'valid_loss': mean_val_loss,\n",
    "                           'valid_acc': mean_val_acc})\n",
    "\n",
    "\n",
    "                # save best models\n",
    "                if highest_valid_acc < mean_val_acc:\n",
    "                    highest_valid_acc = mean_val_acc\n",
    "                    print('ACCURACY for highest valid acc: ', mean_val_acc)\n",
    "                    print('LOSS for lowest valid acc: ', mean_val_loss)\n",
    "                    model.save_pretrained('./best_models/model' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)) + RUNNAME)\n",
    "\n",
    "                elif lowest_valid_loss > mean_val_loss:\n",
    "                    lowest_valid_loss = mean_val_loss\n",
    "                    print('ACCURACY for lowest valid loss: ', mean_val_acc)\n",
    "                    print('LOSS for lowest valid loss: ', mean_val_loss)\n",
    "                    model.save_pretrained('./best_models/model' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)) + RUNNAME)\n",
    "                                        \n",
    "                model.train()\n",
    "                                        \n",
    "                model.train()\n",
    "model.save_pretrained('./best_models/model' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)) + RUNNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sw0Qxy1cJl8H"
   },
   "source": [
    "# SAVE SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 550,
     "status": "aborted",
     "timestamp": 1648812532260,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "QEdp9GAfGCkM"
   },
   "outputs": [],
   "source": [
    "# using pickle, save dump accuracy, loss file to use later when visualizing scores\n",
    "\n",
    "accloss_filename = 'accloss' + str(int(mean_train_acc*100)) + str(int(mean_train_loss*1000)) + RUNNAME + '.p'\n",
    "with open('./scores/' + accloss_filename,'wb') as f:\n",
    "    pickle.dump(train_acc, f)\n",
    "    pickle.dump(train_loss, f)\n",
    "    pickle.dump(valid_acc, f)\n",
    "    pickle.dump(valid_loss, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRK2EOK-JmVe"
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 551,
     "status": "aborted",
     "timestamp": 1648812532261,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "xq0BnOpiGChv"
   },
   "outputs": [],
   "source": [
    "# test model\n",
    "\n",
    "predictions = test_model(model, tokenizer, mean_val_acc, mean_val_loss, file_name = 'test_no_label', device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iFjfVOvJm0S"
   },
   "source": [
    "# SCORE VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 551,
     "status": "aborted",
     "timestamp": 1648812532261,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "mlexaMn9GCfM"
   },
   "outputs": [],
   "source": [
    "# plot accuracy, loss graph for train, valid datasets from saved score pickle data\n",
    "\n",
    "plot_graph(accloss_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 551,
     "status": "aborted",
     "timestamp": 1648812532262,
     "user": {
      "displayName": "조현수",
      "userId": "06575509224308139266"
     },
     "user_tz": -540
    },
    "id": "0TPOTwr0GB4o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhB6GhWLIsH56rqzUe10Z3",
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Yelp_Sentiment_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
