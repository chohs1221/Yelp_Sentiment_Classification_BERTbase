{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yelp_Sentiment_Classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","background_execution":"on","authorship_tag":"ABX9TyPlulUlbgND+QZwlaEbpezv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# INSTALL REQUIREMENTS"],"metadata":{"id":"D5X_UZ62IpMI"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiCBf045Fxs5","executionInfo":{"status":"ok","timestamp":1648725362834,"user_tz":-540,"elapsed":9406,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"14f6be1f-f667-4828-ca8a-d67fcde7634c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.4 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 52.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 52.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 72.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.17.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["# for XLNet\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VfFJlX78OAh5","executionInfo":{"status":"ok","timestamp":1648725366114,"user_tz":-540,"elapsed":3283,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"f6e0711b-45c5-4f2e-977e-0a79ef98c510"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPQia2NjWfII","executionInfo":{"status":"ok","timestamp":1648725373725,"user_tz":-540,"elapsed":7615,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"e1f094ea-c210-4f7c-9b2c-adaa6b59b851"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.11-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 44.2 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.8-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 75.0 MB/s \n","\u001b[?25hCollecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a18e9a3dec00d08396a263c87a3c63e96b1e6ae321aaa3f3902a75b204b4ac3e\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, yaspin, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.8 setproctitle-1.2.2 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.11 yaspin-2.1.0\n"]}]},{"cell_type":"markdown","source":["# GOOGLE MOUNT"],"metadata":{"id":"TAnXdrLQI0Cf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","PATH = './drive/MyDrive/datasets/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"asmIBqBsF-Y6","executionInfo":{"status":"ok","timestamp":1648725430589,"user_tz":-540,"elapsed":56883,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"5f50393c-8363-44af-fc3a-5ffd07d7f080"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/groom_project1/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lkq64JwCG5-s","executionInfo":{"status":"ok","timestamp":1648725430589,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"2c7d335e-57dc-4c1d-f76a-a357a82351c8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/groom_project1\n"]}]},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Y25vO7PrG-GW","executionInfo":{"status":"ok","timestamp":1648725430590,"user_tz":-540,"elapsed":6,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"d22fa593-7b71-4220-fd79-7aef7977821d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/groom_project1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# IMPORT REQUIREMENTS"],"metadata":{"id":"lPhgURY0I5yf"}},{"cell_type":"code","source":["import os\n","import sys\n","import random\n","import pickle\n","\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from transformers import (\n","    AdamW\n",")\n","\n","import wandb\n","\n","# import costumized modules\n","from compute import compute_acc\n","from visualize_score import plot_graph\n","from dump_datasets import mk_dataset, mk_dataset_xlnet\n","from dump_models import load_model, load_model_xlnet\n","from evaluate import test_model\n","from data_processing import regular"],"metadata":{"id":"0DJZhXDiF_q8","executionInfo":{"status":"ok","timestamp":1648725441190,"user_tz":-540,"elapsed":10605,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#CREATE FOLDER"],"metadata":{"id":"_s6-hdcnJE4o"}},{"cell_type":"code","source":["# create required folders if not exists\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print ('Error: Creating directory. ' +  directory)\n"," \n","createFolder('./best_models')\n","createFolder('./dump_datasets')\n","createFolder('./dump_models_tokenizer')\n","createFolder('./scores')\n","createFolder('./submissions')"],"metadata":{"id":"zpwJUy-bGBGV","executionInfo":{"status":"ok","timestamp":1648725441190,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# FIX SEED"],"metadata":{"id":"MF56rfhfJIRV"}},{"cell_type":"code","source":["def seed_everything(seed:int = 1004):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_everything(42)"],"metadata":{"id":"X4M_6OCAGC5r","executionInfo":{"status":"ok","timestamp":1648725441191,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# MODEL"],"metadata":{"id":"KgGB8K4yJNUy"}},{"cell_type":"code","source":["# test various models\n","MODEL_NAME = 'bert-base-uncased'\n","# MODEL_NAME = 'bert-large-uncased'\n","# MODEL_NAME = 'xlnet-base-cased'\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","assert str(device) == 'cuda'\n","\n","# by using pickle, load dump file if exist, else make dump file and load\n","# load for bert(uncased) or xlnet model(cased)\n","try:\n","    with open('./dump_models_tokenizer/' + MODEL_NAME + '.p', 'rb') as f:\n","        model = pickle.load(f)\n","        tokenizer = pickle.load(f)\n","        print('./dump_models_tokenizer/' + MODEL_NAME + '.p')\n","    print('model exists => just load model')\n","except:\n","    print('exeption occur => download model')\n","    if MODEL_NAME == 'bert-base-uncased':\n","        model, tokenizer = load_model(MODEL_NAME)\n","    elif MODEL_NAME == 'xlnet-base-cased':\n","        model, tokenizer = load_model_xlnet(MODEL_NAME)\n","\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBdaD3ZYGC3U","executionInfo":{"status":"ok","timestamp":1648725458450,"user_tz":-540,"elapsed":17267,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"da916423-2e42-46a5-e0d9-164dbbe1095e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["./dump_models_tokenizer/bert-base-uncased.p\n","model exists => just load model\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# HYPER PARAMETERS"],"metadata":{"id":"5T7lNCeDJQQY"}},{"cell_type":"code","source":["TRAIN_BATCH_SIZE=256\n","EVAL_BATCH_SIZE=256\n","\n","LEARNING_RATE = 5e-5\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","TRAIN_EPOCH = 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsvhsrAkGC1A","executionInfo":{"status":"ok","timestamp":1648725458451,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"a378e7ce-1098-4ff7-f744-786bc432f9a3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","source":["# WANDB"],"metadata":{"id":"bqrBw8DT6zM2"}},{"cell_type":"code","source":["!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivKiMQWk7WAR","executionInfo":{"status":"ok","timestamp":1648725504809,"user_tz":-540,"elapsed":46367,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"2751e875-2bc9-43c6-9de0-ad6dc4b1eac2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["wandb.init(project=\"groomProject1\", entity=\"chohs1221\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"NWHyxG8UWxEs","executionInfo":{"status":"ok","timestamp":1648725510644,"user_tz":-540,"elapsed":5859,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"95600ce9-cae6-457e-9713-4400309bea1e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/groom_project1/wandb/run-20220331_111826-wo5ufdhf</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/chohs1221/groomProject1/runs/wo5ufdhf\" target=\"_blank\">icy-pine-6</a></strong> to <a href=\"https://wandb.ai/chohs1221/groomProject1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/chohs1221/groomProject1/runs/wo5ufdhf?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f1a81f2c290>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["wandb.run.name = 'bert2_lr' + str(LEARNING_RATE)"],"metadata":{"id":"LhQQiGsq8S47","executionInfo":{"status":"ok","timestamp":1648725510644,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["wandb.config.learning_rate = LEARNING_RATE\n","wandb.config.epochs = TRAIN_EPOCH\n","wandb.config.batch_size = TRAIN_BATCH_SIZE"],"metadata":{"id":"u0iiLeKlsF-n","executionInfo":{"status":"ok","timestamp":1648725510644,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# LOAD DATASETS"],"metadata":{"id":"uL9a89s6JSSW"}},{"cell_type":"code","source":["# by using pickle, load dump file if exist, else make dump file and load\n","# load for bert(uncased) or xlnet model(cased)\n","try:\n","    if  MODEL_NAME == 'bert-base-uncased':\n","        with open('./dump_datasets/train_dev_dumps.p', 'rb') as f:\n","            train_pos = pickle.load(f)\n","            train_neg = pickle.load(f)\n","            dev_pos = pickle.load(f)\n","            dev_neg = pickle.load(f)\n","        print('dataset exists => just load datasets')\n","    elif  MODEL_NAME == 'xlnet-base-cased':\n","        with open('./dump_datasets/train_dev_dumps_xlnet.p', 'rb') as f:\n","            train_pos = pickle.load(f)\n","            train_neg = pickle.load(f)\n","            dev_pos = pickle.load(f)\n","            dev_neg = pickle.load(f)\n","        print('dataset exists => just load datasets')\n","except:\n","    print('exeption occur => make datasets')\n","    train_pos, train_neg, dev_pos, dev_neg = mk_dataset()\n","    if MODEL_NAME == 'bert-base-uncased':\n","        train_pos, train_neg, dev_pos, dev_neg = mk_dataset()\n","    elif MODEL_NAME == 'xlnet-base-cased':\n","        train_pos, train_neg, dev_pos, dev_neg = mk_dataset_xlnet()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6OctK41GCyh","executionInfo":{"status":"ok","timestamp":1648725511143,"user_tz":-540,"elapsed":501,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"1b5c628e-b218-4135-b98c-d9bc92ce170d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset exists => just load datasets\n"]}]},{"cell_type":"markdown","source":["# DATA PREPROCESSING"],"metadata":{"id":"j-LaQPSMJYsn"}},{"cell_type":"code","source":["# Remove '_num_', !@#$ ... from datasets\n","# train_pos = regular(train_pos)\n","# train_neg = regular(train_pos)\n","# dev_pos = regular(train_pos)\n","# dev_neg = regular(train_pos)"],"metadata":{"id":"yISja4bWGCwS","executionInfo":{"status":"ok","timestamp":1648725511144,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# TOKENIZE"],"metadata":{"id":"16_--kIMJbZA"}},{"cell_type":"code","source":["# seperate encoding to preprocess data before encoding\n","train_pos = [tokenizer.encode(line) for line in train_pos]\n","train_neg = [tokenizer.encode(line) for line in train_neg]\n","dev_pos = [tokenizer.encode(line) for line in dev_pos]\n","dev_neg = [tokenizer.encode(line) for line in dev_neg]"],"metadata":{"id":"pP5IkQA-GCt9","executionInfo":{"status":"ok","timestamp":1648725661385,"user_tz":-540,"elapsed":150243,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# MAKE DATASETS"],"metadata":{"id":"NLJLDMjJJc-X"}},{"cell_type":"code","source":["# concatenate pos, neg dataset, costomize magic mathod\n","class SentimentDataset(object):\n","    def __init__(self, pos, neg):\n","        self.data = [pos_sent for pos_sent in pos] + [neg_sent for neg_sent in neg]\n","        self.label = [[1] for _ in range(len(pos))] + [[0] for _ in range(len(neg))]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample), np.array(self.label[index])\n","\n","train_dataset = SentimentDataset(train_pos, train_neg)\n","dev_dataset = SentimentDataset(dev_pos, dev_neg)"],"metadata":{"id":"0NvG4M4SGCre","executionInfo":{"status":"ok","timestamp":1648725662312,"user_tz":-540,"elapsed":937,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# DATA LOADER"],"metadata":{"id":"wBtcDb_JJgDI"}},{"cell_type":"code","source":["# argsort deleted <- no reason to sort\n","# attention masking for padding token\n","def collate_fn_style(samples):\n","    input_ids, labels = zip(*samples)\n","    max_len = max(len(input_id) for input_id in input_ids)\n","\n","    attention_mask = torch.tensor([[1] * len(input_id) + [0] * (max_len - len(input_id)) for input_id in input_ids])\n","    input_ids = pad_sequence([torch.tensor(input_id) for input_id in input_ids], batch_first=True)\n","    token_type_ids = torch.tensor([[0] * len(input_id) for input_id in input_ids])\n","    position_ids = torch.tensor([list(range(len(input_id))) for input_id in input_ids])\n","    labels = torch.tensor(np.stack(labels, axis=0))\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids, labels\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=TRAIN_BATCH_SIZE,\n","                                           shuffle=True, \n","                                           collate_fn=collate_fn_style,\n","                                           pin_memory=True, num_workers=2)\n","\n","dev_loader = torch.utils.data.DataLoader(dev_dataset, \n","                                         batch_size=EVAL_BATCH_SIZE,\n","                                         shuffle=False, \n","                                         collate_fn=collate_fn_style,\n","                                         num_workers=2)"],"metadata":{"id":"_W2NP0EtGCpI","executionInfo":{"status":"ok","timestamp":1648725662313,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# TRAIN"],"metadata":{"id":"SZvq41xfJif7"}},{"cell_type":"code","source":["# record datas for highest accuracy & lowest loss\n","lowest_valid_loss = 9999.\n","highest_valid_acc = 0.\n","train_acc = []\n","train_loss = []\n","valid_acc = []\n","valid_loss = []\n","\n","temp_train_acc = []\n","temp_train_loss = []\n","\n","#train model\n","model.train()\n","for epoch in range(TRAIN_EPOCH):\n","    with tqdm(train_loader, unit=\"batch\") as tepoch:\n","        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n","\n","            tepoch.set_description(f\"Epoch {epoch}\")\n","\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            position_ids = position_ids.to(device)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            output = model(input_ids=input_ids,\n","                           attention_mask=attention_mask,\n","                           token_type_ids=token_type_ids,\n","                           position_ids=position_ids,\n","                           labels=labels)\n","\n","            loss = output.loss\n","            \n","            logits = output.logits\n","            batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","            batch_labels = [int(example) for example in labels]\n","            \n","            acc = compute_acc(batch_predictions, batch_labels)\n","            \n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","\n","            tepoch.set_postfix(acc=acc, loss=loss.item())\n","            \n","            temp_train_acc.append(acc)\n","            temp_train_loss.append(loss.item())\n","            if iteration != 0 and iteration % int(len(train_loader) / 100) == 0:\n","\n","                # evaluate model\n","                model.eval()\n","                with torch.no_grad():\n","                    val_acc = []\n","                    val_loss = []\n","                    for input_ids, attention_mask, token_type_ids, position_ids, labels in dev_loader:\n","                        input_ids = input_ids.to(device)\n","                        attention_mask = attention_mask.to(device)\n","                        token_type_ids = token_type_ids.to(device)\n","                        position_ids = position_ids.to(device)\n","                        labels = labels.to(device, dtype=torch.long)\n","\n","                        output = model(input_ids=input_ids,\n","                                    attention_mask=attention_mask,\n","                                    token_type_ids=token_type_ids,\n","                                    position_ids=position_ids,\n","                                    labels=labels)\n","\n","                        logits = output.logits\n","                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","                        batch_labels = [int(example) for example in labels]\n","\n","                        val_acc.append(compute_acc(batch_predictions, batch_labels))\n","                        val_loss.append(output.loss)\n","\n","                # compute accuracy, loss for train, valid datasets and record\n","                mean_train_acc = sum(temp_train_acc) / len(temp_train_acc)\n","                mean_train_loss = sum(temp_train_loss) / len(temp_train_loss)\n","                mean_val_acc = sum(val_acc) / len(val_acc)\n","                mean_val_loss = sum(val_loss) / len(val_loss)\n","\n","                train_acc.append(mean_train_acc)\n","                train_loss.append(mean_train_loss)\n","                valid_acc.append(mean_val_acc)\n","                valid_loss.append(mean_val_loss)\n","\n","                temp_train_acc = []\n","                temp_train_loss = []\n","                \n","                # WANDB\n","                wandb.log({\"train_loss\": mean_train_loss,\n","                           'train_acc': mean_train_acc,\n","                           'valid_loss': mean_val_loss,\n","                           'valid_acc': mean_val_acc})\n","\n","                # save best models\n","                if highest_valid_acc < mean_val_acc:\n","                    highest_valid_acc = mean_val_acc\n","                    print('ACCURACY for highest valid acc: ', mean_val_acc)\n","                    print('LOSS for lowest valid acc: ', mean_val_loss)\n","                    # model.save_pretrained('./best_models/model' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)))\n","\n","                elif lowest_valid_loss > mean_val_loss:\n","                    lowest_valid_loss = mean_val_loss\n","                    print('ACCURACY for lowest valid loss: ', mean_val_acc)\n","                    print('LOSS for lowest valid loss: ', mean_val_loss)\n","                    # model.save_pretrained('./best_models/model' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)))\n","                                        \n","                model.train()\n","model.save_pretrained('./best_models/model' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EaiyTjucGCmq","outputId":"d809db30-f2dc-4a04-b36c-2a9f6f36cf62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 0:   1%|          | 18/1732 [00:13<41:17,  1.45s/batch, acc=0.965, loss=0.102]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.956884765625\n","LOSS for lowest valid acc:  tensor(0.1374, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   2%|▏         | 35/1732 [00:25<40:20,  1.43s/batch, acc=0.945, loss=0.157]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.959423828125\n","LOSS for lowest valid acc:  tensor(0.1136, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   3%|▎         | 52/1732 [00:37<39:55,  1.43s/batch, acc=0.984, loss=0.0618]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.964111328125\n","LOSS for lowest valid acc:  tensor(0.1033, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   4%|▍         | 69/1732 [00:49<39:13,  1.42s/batch, acc=0.949, loss=0.126]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.95908203125\n","LOSS for lowest valid loss:  tensor(0.1058, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   5%|▍         | 86/1732 [01:01<39:06,  1.43s/batch, acc=0.965, loss=0.0759]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.95966796875\n","LOSS for lowest valid loss:  tensor(0.1043, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   6%|▌         | 103/1732 [01:13<39:24,  1.45s/batch, acc=0.973, loss=0.0841]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.9701171875\n","LOSS for lowest valid acc:  tensor(0.0853, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   7%|▋         | 120/1732 [01:25<38:24,  1.43s/batch, acc=0.965, loss=0.104]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.967041015625\n","LOSS for lowest valid loss:  tensor(0.0936, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:   8%|▊         | 137/1732 [01:36<37:31,  1.41s/batch, acc=0.977, loss=0.0623]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.970751953125\n","LOSS for lowest valid acc:  tensor(0.0796, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  10%|▉         | 171/1732 [02:00<36:50,  1.42s/batch, acc=0.953, loss=0.111]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.9732421875\n","LOSS for lowest valid acc:  tensor(0.0789, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  11%|█         | 188/1732 [02:12<36:48,  1.43s/batch, acc=0.957, loss=0.109]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.969873046875\n","LOSS for lowest valid loss:  tensor(0.0839, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  12%|█▏        | 205/1732 [02:24<36:12,  1.42s/batch, acc=0.988, loss=0.0484]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.975537109375\n","LOSS for lowest valid acc:  tensor(0.0745, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  13%|█▎        | 222/1732 [02:36<35:49,  1.42s/batch, acc=0.965, loss=0.0722]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.97255859375\n","LOSS for lowest valid loss:  tensor(0.0777, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  17%|█▋        | 290/1732 [03:24<34:19,  1.43s/batch, acc=0.969, loss=0.0635]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.973193359375\n","LOSS for lowest valid loss:  tensor(0.0774, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  18%|█▊        | 307/1732 [03:37<34:25,  1.45s/batch, acc=0.965, loss=0.0904]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.972119140625\n","LOSS for lowest valid loss:  tensor(0.0731, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  20%|█▉        | 341/1732 [04:01<33:13,  1.43s/batch, acc=0.98, loss=0.0482]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.97666015625\n","LOSS for lowest valid acc:  tensor(0.0658, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  21%|██        | 358/1732 [04:13<32:49,  1.43s/batch, acc=0.977, loss=0.0567]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.975927734375\n","LOSS for lowest valid loss:  tensor(0.0665, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  24%|██▎       | 409/1732 [04:49<31:39,  1.44s/batch, acc=0.977, loss=0.0764]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.9771484375\n","LOSS for lowest valid acc:  tensor(0.0651, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  30%|███       | 528/1732 [06:13<28:50,  1.44s/batch, acc=0.98, loss=0.0721]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for highest valid acc:  0.978857421875\n","LOSS for lowest valid acc:  tensor(0.0649, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  34%|███▍      | 596/1732 [07:01<26:57,  1.42s/batch, acc=0.98, loss=0.0692]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.975927734375\n","LOSS for lowest valid loss:  tensor(0.0620, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  38%|███▊      | 664/1732 [07:49<25:29,  1.43s/batch, acc=0.98, loss=0.0666]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.976025390625\n","LOSS for lowest valid loss:  tensor(0.0610, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  40%|████      | 698/1732 [08:13<25:10,  1.46s/batch, acc=0.961, loss=0.0883]"]},{"output_type":"stream","name":"stdout","text":["ACCURACY for lowest valid loss:  0.978125\n","LOSS for lowest valid loss:  tensor(0.0576, device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  41%|████      | 714/1732 [08:21<09:06,  1.86batch/s, acc=0.973, loss=0.0541]"]}]},{"cell_type":"markdown","source":["# SAVE SCORES"],"metadata":{"id":"sw0Qxy1cJl8H"}},{"cell_type":"code","source":["# using pickle, save dump accuracy, loss file\n","accloss_filename = 'accloss' + str(int(mean_val_acc*100)) + str(int(mean_val_loss*1000)) + '.p'\n","with open('./scores/' + accloss_filename,'wb') as f:\n","    pickle.dump(train_acc, f)\n","    pickle.dump(train_loss, f)\n","    pickle.dump(valid_acc, f)\n","    pickle.dump(valid_loss, f)"],"metadata":{"id":"QEdp9GAfGCkM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TEST"],"metadata":{"id":"HRK2EOK-JmVe"}},{"cell_type":"code","source":["# test model\n","test_model(model, tokenizer, mean_val_acc, mean_val_loss, file_name = 'test_no_label', device='cuda')"],"metadata":{"id":"xq0BnOpiGChv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SCORE VISUALIZE"],"metadata":{"id":"5iFjfVOvJm0S"}},{"cell_type":"code","source":["# plot accuracy, loss graph for train, valid datasets\n","plot_graph(accloss_filename)"],"metadata":{"id":"mlexaMn9GCfM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0TPOTwr0GB4o"},"execution_count":null,"outputs":[]}]}